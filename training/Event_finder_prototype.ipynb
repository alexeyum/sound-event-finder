{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference\n",
        "\n",
        "- [AudioSet](https://research.google.com/audioset/)"
      ],
      "metadata": {
        "id": "9Q6hZo0vxpR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More model ideas\n",
        "\n",
        "- Other (smaller) versions of AST\n",
        "\n",
        "- https://huggingface.co/topel/ConvNeXt-Tiny-AT\n",
        "\n",
        "- https://huggingface.co/search/full-text?q=audioset&p=1&type=model\n",
        "\n",
        "- https://paperswithcode.com/paper/efficient-large-scale-audio-tagging-via\n",
        "\n",
        "- https://paperswithcode.com/paper/dynamic-convolutional-neural-networks-as\n",
        "\n",
        "- https://paperswithcode.com/paper/panns-large-scale-pretrained-audio-neural-1"
      ],
      "metadata": {
        "id": "fbXG0AOBD7au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, installs, etc."
      ],
      "metadata": {
        "id": "OkiYq093brGT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jry1D7yIY8i0"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torchaudio"
      ],
      "metadata": {
        "id": "gMrpkwooZioF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxHmq2dqzTFO",
        "outputId": "fd88f475-867a-4d08-cffc-c9b53eb5e4b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: move to the library?\n",
        "\n",
        "def downmix_to_mono(waveform):\n",
        "    return waveform.mean(dim=0)\n",
        "\n",
        "def preprocess(waveform, sampling_rate, target_sampling_rate):\n",
        "    waveform = downmix_to_mono(waveform)\n",
        "    return torchaudio.functional.resample(waveform, sampling_rate, target_sampling_rate)"
      ],
      "metadata": {
        "id": "pYrQuHBELLb-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./drive/MyDrive/Projects/MiniSoundFinder_v2/samples/* ."
      ],
      "metadata": {
        "id": "rstRJBCzaWfm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = 'freesound_442485_dogs_barking_60sec.wav'\n",
        "print(torchaudio.info(sample_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jjTHE1kbd0Y",
        "outputId": "1caca283-76e4-4b18-9ffd-c0780a28ed7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AudioMetaData(sample_rate=48000, num_frames=2847537, num_channels=2, bits_per_sample=24, encoding=PCM_S)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, sampling_rate = torchaudio.load(sample_path)\n",
        "waveform.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3B450xZb0z3",
        "outputId": "6280722b-8cdb-48eb-ad40-3f6b56775c87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2847537])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wf_prep = preprocess(waveform, sampling_rate, 16000)\n",
        "wf_prep.shape"
      ],
      "metadata": {
        "id": "0OSwwkRieBsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ad234e-3d35-45bb-8aeb-cd13c9186a12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([949179])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "PyeBiD3Vbvor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AST"
      ],
      "metadata": {
        "id": "4iG8YpP_Cg1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [AST on HuggingFace](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)\n",
        "\n",
        "- [AST Paper](https://arxiv.org/pdf/2104.01778.pdf)"
      ],
      "metadata": {
        "id": "nJ4iICl6Chyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, ASTForAudioClassification"
      ],
      "metadata": {
        "id": "RUjCAaucCxj-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_ast = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "extractor_ast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lIQe-CVZo7_",
        "outputId": "4ea4d86a-4691-4a68-d12f-f3c580704e00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n",
              "  \"feature_size\": 1,\n",
              "  \"max_length\": 1024,\n",
              "  \"mean\": -4.2677393,\n",
              "  \"num_mel_bins\": 128,\n",
              "  \"padding_side\": \"right\",\n",
              "  \"padding_value\": 0.0,\n",
              "  \"return_attention_mask\": false,\n",
              "  \"sampling_rate\": 16000,\n",
              "  \"std\": 4.5689974\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ast = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\").to(DEVICE)\n",
        "model_ast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZETaSypVbBHl",
        "outputId": "2d56ce6e-a40c-46a5-f83b-3a6fc4cffc83"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTForAudioClassification(\n",
              "  (audio_spectrogram_transformer): ASTModel(\n",
              "    (embeddings): ASTEmbeddings(\n",
              "      (patch_embeddings): ASTPatchEmbeddings(\n",
              "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ASTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ASTLayer(\n",
              "          (attention): ASTAttention(\n",
              "            (attention): ASTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ASTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ASTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ASTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): ASTMLPHead(\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_sampling_rate = extractor_ast.sampling_rate\n",
        "wf_prep = preprocess(waveform, sampling_rate, target_sampling_rate)\n",
        "sample_features = extractor_ast(wf_prep, target_sampling_rate, return_tensors=\"pt\").to(DEVICE)\n",
        "sample_features['input_values'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5dFfpx5cUD7",
        "outputId": "b1756b8f-3353-46ce-b20d-b9da171d74e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    probs = torch.sigmoid(model_ast(**sample_features).logits)"
      ],
      "metadata": {
        "id": "uiE_guEFeh_D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_classes = torch.argsort(probs, dim=-1, descending=True).flatten()[:10]\n",
        "top_labels = [(model_ast.config.id2label[id.item()], probs[0, id].item()) for id in top_classes]\n",
        "top_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jY7kN_2exFT",
        "outputId": "3e002646-9d33-4971-e511-2c3e68aab8e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dog', 0.7794266939163208),\n",
              " ('Animal', 0.7416857481002808),\n",
              " ('Domestic animals, pets', 0.6783860325813293),\n",
              " ('Bark', 0.6013593673706055),\n",
              " ('Bow-wow', 0.4377628266811371),\n",
              " ('Canidae, dogs, wolves', 0.19103211164474487),\n",
              " ('Yip', 0.10324634611606598),\n",
              " ('Whimper (dog)', 0.06323516368865967),\n",
              " ('Vehicle', 0.025787750259041786),\n",
              " ('Growling', 0.019477838650345802)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time_ast(model, feature_extractor,\n",
        "                               sample_length_sec=60,\n",
        "                               repeats=20,\n",
        "                               chunk_length_sec=10):\n",
        "\n",
        "    sampling_rate = feature_extractor.sampling_rate\n",
        "    sample_length = sampling_rate * sample_length_sec\n",
        "\n",
        "    extr_times = []\n",
        "    inf_times = []\n",
        "    for i in range(repeats):\n",
        "        extr_start = time.time()\n",
        "        wf = torch.distributions.uniform.Uniform(-10000, 10000).sample((sample_length,))\n",
        "        chunk_length = chunk_length_sec * sampling_rate\n",
        "        chunks = [c.numpy() for c in torch.split(wf, chunk_length)]\n",
        "        inp = feature_extractor(chunks, sampling_rate, return_tensors=\"pt\").to(DEVICE)\n",
        "        extr_times.append(time.time() - extr_start)\n",
        "\n",
        "        inf_start = time.time()\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(model(**inp).logits)\n",
        "        inf_times.append(time.time() - inf_start)\n",
        "\n",
        "    print(\"Extraction:\", np.mean(extr_times), \"±\", np.std(extr_times))\n",
        "    print(\"Inference:\", np.mean(inf_times), \"±\", np.std(inf_times))\n",
        "\n",
        "print(\"1 minute\")\n",
        "measure_inference_time_ast(model_ast, extractor_ast, sample_length_sec=60)\n",
        "print()\n",
        "\n",
        "print(\"2 minutes\")\n",
        "measure_inference_time_ast(model_ast, extractor_ast, sample_length_sec=120)\n",
        "print()\n",
        "\n",
        "print(\"5 minutes\")\n",
        "measure_inference_time_ast(model_ast, extractor_ast, sample_length_sec=300)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVZJUmKlMiI7",
        "outputId": "22f656ee-33d8-4b14-f9f4-e075da0c4394"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 minute\n",
            "Extraction: 0.49896767139434817 ± 0.05701984130123135\n",
            "Inference: 0.06294565200805664 ± 0.12200481841226771\n",
            "\n",
            "2 minutes\n",
            "Extraction: 1.0849987626075746 ± 0.13093320682879783\n",
            "Inference: 0.03713115453720093 ± 0.017910840644628657\n",
            "\n",
            "5 minutes\n",
            "Extraction: 2.624024844169617 ± 0.5936241239571343\n",
            "Inference: 0.15126835107803344 ± 0.6031503484581417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AST Distilled"
      ],
      "metadata": {
        "id": "wNbL8N75CmhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/bookbot/distil-ast-audioset"
      ],
      "metadata": {
        "id": "_cLUTmp4D4CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_ast_distil = AutoFeatureExtractor.from_pretrained(\"bookbot/distil-ast-audioset\")\n",
        "extractor_ast_distil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ci69tKRiBb",
        "outputId": "adef6899-e3df-454e-8d15-3b90a07d649c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n",
              "  \"feature_size\": 1,\n",
              "  \"max_length\": 1024,\n",
              "  \"mean\": -4.2677393,\n",
              "  \"num_mel_bins\": 128,\n",
              "  \"padding_side\": \"right\",\n",
              "  \"padding_value\": 0.0,\n",
              "  \"return_attention_mask\": false,\n",
              "  \"sampling_rate\": 16000,\n",
              "  \"std\": 4.5689974\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ast_distil = ASTForAudioClassification.from_pretrained(\"bookbot/distil-ast-audioset\").to(DEVICE)\n",
        "model_ast_distil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExztmUmGCrBv",
        "outputId": "f0bda61e-dfed-4b46-f12c-231971e007c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTForAudioClassification(\n",
              "  (audio_spectrogram_transformer): ASTModel(\n",
              "    (embeddings): ASTEmbeddings(\n",
              "      (patch_embeddings): ASTPatchEmbeddings(\n",
              "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ASTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x ASTLayer(\n",
              "          (attention): ASTAttention(\n",
              "            (attention): ASTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ASTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ASTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ASTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): ASTMLPHead(\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_sampling_rate = extractor_ast_distil.sampling_rate\n",
        "wf_prep = preprocess(waveform, sampling_rate, target_sampling_rate)\n",
        "sample_features = extractor_ast_distil(wf_prep, target_sampling_rate, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    probs = torch.sigmoid(model_ast_distil(**sample_features).logits)\n",
        "\n",
        "top_classes = torch.argsort(probs, dim=-1, descending=True).flatten()[:10]\n",
        "top_labels = [(model_ast.config.id2label[id.item()], probs[0, id].item()) for id in top_classes]\n",
        "top_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L37gqz9xMVoW",
        "outputId": "f262a15e-bb18-4a91-9c8b-ff26f29cf046"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Animal', 0.8284617066383362),\n",
              " ('Dog', 0.7962838411331177),\n",
              " ('Domestic animals, pets', 0.7366085052490234),\n",
              " ('Bark', 0.5144543051719666),\n",
              " ('Bow-wow', 0.4676071107387543),\n",
              " ('Speech', 0.3647525906562805),\n",
              " ('Canidae, dogs, wolves', 0.18395470082759857),\n",
              " ('Yip', 0.1634257733821869),\n",
              " ('Whimper (dog)', 0.15281470119953156),\n",
              " ('Growling', 0.05686230957508087)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1 minute\")\n",
        "measure_inference_time_ast(model_ast_distil, extractor_ast_distil, sample_length_sec=60)\n",
        "print()\n",
        "\n",
        "print(\"2 minutes\")\n",
        "measure_inference_time_ast(model_ast_distil, extractor_ast_distil, sample_length_sec=120)\n",
        "print()\n",
        "\n",
        "print(\"5 minutes\")\n",
        "measure_inference_time_ast(model_ast_distil, extractor_ast_distil, sample_length_sec=300)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT0hsFaORYlO",
        "outputId": "b060ae56-fc9e-494e-b0a2-c1f1ec99011e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 minute\n",
            "Extraction: 0.27698051929473877 ± 0.03136304936199706\n",
            "Inference: 0.01278308629989624 ± 0.004615448690231693\n",
            "\n",
            "2 minutes\n",
            "Extraction: 0.5859007120132447 ± 0.06715868676346086\n",
            "Inference: 0.01448047161102295 ± 0.007278011488104042\n",
            "\n",
            "5 minutes\n",
            "Extraction: 1.4067103147506714 ± 0.1870556772212367\n",
            "Inference: 0.008913743495941161 ± 0.004447023831099555\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Event finder"
      ],
      "metadata": {
        "id": "PE5BmHwm0Wxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: move to the library?\n",
        "\n",
        "def continuos_segments(values):\n",
        "    start = -1\n",
        "    for i in range(len(values)):\n",
        "        if values[i]:\n",
        "            if start == -1:\n",
        "                start = i\n",
        "        else:\n",
        "            if start != -1:\n",
        "                yield (start, i)\n",
        "            start = -1\n",
        "    if start != -1:\n",
        "        yield (start, len(values))\n",
        "\n",
        "\n",
        "class EventFinder:\n",
        "    def __init__(self, feature_extractor, model, chunk_length_sec, prob_threshold=0.3):\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.target_sampling_rate = self.feature_extractor.sampling_rate\n",
        "        self.model = model\n",
        "        self.chunk_length_sec = chunk_length_sec\n",
        "\n",
        "        # TMP\n",
        "        self.event_classes = [\n",
        "            74,   # Dog\n",
        "            137,  # Music\n",
        "            300,  # Vehicle\n",
        "            0,    # Speech\n",
        "            117,  # Crow\n",
        "            112,  # Bird vocalization, bird call, bird song\n",
        "        ]\n",
        "        self.prob_threshold = prob_threshold\n",
        "\n",
        "    def compute_probabilities(self, audio_path):\n",
        "        waveform_raw, sampling_rate = torchaudio.load(audio_path)\n",
        "        waveform = preprocess(waveform_raw, sampling_rate, self.target_sampling_rate)\n",
        "\n",
        "        chunk_length = self.chunk_length_sec * self.target_sampling_rate\n",
        "        chunks = [c.numpy() for c in torch.split(waveform, chunk_length)]\n",
        "\n",
        "        features = self.feature_extractor(chunks, self.target_sampling_rate, return_tensors=\"pt\").to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(self.model(**features).logits)\n",
        "        return probs\n",
        "\n",
        "    def find_events(self, audio_path):\n",
        "        probs = self.compute_probabilities(audio_path)\n",
        "\n",
        "        events = []\n",
        "        for class_ind in self.event_classes:\n",
        "            class_name = self.model.config.id2label[class_ind]\n",
        "            class_parts = probs[:, class_ind] >= self.prob_threshold\n",
        "            for begin, end in continuos_segments(class_parts):\n",
        "                begin_sec = begin * self.chunk_length_sec\n",
        "                end_sec = end * self.chunk_length_sec\n",
        "                events.append((class_name, begin_sec, end_sec))\n",
        "\n",
        "        events.sort(key=lambda e: e[1])\n",
        "\n",
        "        return probs, events\n",
        "\n",
        "\n",
        "\n",
        "finder = EventFinder(extractor_ast, model_ast,\n",
        "                     chunk_length_sec=10, prob_threshold=0.2)"
      ],
      "metadata": {
        "id": "gjwg1uPDxIKw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probs, top_labels = finder.find_events('/content/freesound_442485_dogs_barking_60sec.wav')\n",
        "# top_classes = torch.argsort(probs, dim=-1, descending=True)[:, :5]\n",
        "# for i in range(top_classes.shape[0]):\n",
        "#     print([(model.config.id2label[id.item()], id.item(), probs[i, id].item()) for id in top_classes[i]])"
      ],
      "metadata": {
        "id": "3h3DCLAv8ole"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs, events = finder.find_events('/content/freesound_442485_dogs_barking_60sec.wav')\n",
        "events"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHt39kmiRliK",
        "outputId": "0c180510-8dd5-4d80-e4bb-0c4e7eb77299"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dog', 0, 60)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs, events = finder.find_events('/content/freesound_471408_birds_90sec.wav')\n",
        "events"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rle_n6S7BC6",
        "outputId": "43f9c935-c3fb-414a-de3d-a6a6ec5fd0c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Music', 0, 10),\n",
              " ('Crow', 0, 40),\n",
              " ('Bird vocalization, bird call, bird song', 40, 50),\n",
              " ('Crow', 50, 60),\n",
              " ('Bird vocalization, bird call, bird song', 60, 80),\n",
              " ('Crow', 80, 100)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs, events = finder.find_events('/content/recorded_street_150sec.wav')\n",
        "events"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afMdBvpm6og1",
        "outputId": "ab979332-9910-4818-8145-501a3e32dd08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Vehicle', 10, 20),\n",
              " ('Speech', 10, 80),\n",
              " ('Music', 20, 30),\n",
              " ('Vehicle', 40, 90),\n",
              " ('Music', 80, 100),\n",
              " ('Speech', 90, 150)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ef3uhcYz-3II"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}