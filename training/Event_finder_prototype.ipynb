{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference\n",
        "\n",
        "- [AudioSet](https://research.google.com/audioset/)\n",
        "\n",
        "- [AST on HuggingFace](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)\n",
        "\n",
        "- [AST Paper](https://arxiv.org/pdf/2104.01778.pdf)"
      ],
      "metadata": {
        "id": "9Q6hZo0vxpR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, installs, etc."
      ],
      "metadata": {
        "id": "OkiYq093brGT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jry1D7yIY8i0"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from transformers import AutoFeatureExtractor, ASTForAudioClassification"
      ],
      "metadata": {
        "id": "gMrpkwooZioF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxHmq2dqzTFO",
        "outputId": "9862cac5-38da-4077-e927-c6343063c782"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Samples"
      ],
      "metadata": {
        "id": "sWsxd4ctbts8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./drive/MyDrive/Projects/MiniSoundFinder_v2/samples/* ."
      ],
      "metadata": {
        "id": "rstRJBCzaWfm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = 'freesound_442485_dogs_barking_60sec.wav'\n",
        "print(torchaudio.info(sample_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jjTHE1kbd0Y",
        "outputId": "050cedf8-233e-4fa0-85a0-db5b59ee86d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AudioMetaData(sample_rate=48000, num_frames=2847537, num_channels=2, bits_per_sample=24, encoding=PCM_S)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, sample_rate = torchaudio.load(sample_path)\n",
        "waveform.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3B450xZb0z3",
        "outputId": "4545fa5f-c651-4b10-e5af-3018634517fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2847537])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_SAMPLE_RATE = 16000\n",
        "\n",
        "def downmix_to_mono(waveform):\n",
        "    return waveform.mean(dim=0)\n",
        "\n",
        "def preprocess(waveform, sampling_rate, target_sampling_rate=TARGET_SAMPLE_RATE):\n",
        "    waveform = downmix_to_mono(waveform)\n",
        "    return torchaudio.functional.resample(waveform, sampling_rate, target_sampling_rate)"
      ],
      "metadata": {
        "id": "bDz7tWmBdAV4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wf_prep = preprocess(waveform, sample_rate)"
      ],
      "metadata": {
        "id": "0OSwwkRieBsB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wf_prep.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqD_aSdMeHI-",
        "outputId": "5775fea9-14a0-46a7-c9ec-690153448b62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([949179])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wf_prep.shape[0] / TARGET_SAMPLE_RATE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRrDEAKJ1_vO",
        "outputId": "0c68f1fe-de68-4d2b-f2dd-79c8ac1e4588"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59.3236875"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "PyeBiD3Vbvor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "feature_extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lIQe-CVZo7_",
        "outputId": "505c6b81-a3b6-4a20-89ee-34090b0d7047"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n",
              "  \"feature_size\": 1,\n",
              "  \"max_length\": 1024,\n",
              "  \"mean\": -4.2677393,\n",
              "  \"num_mel_bins\": 128,\n",
              "  \"padding_side\": \"right\",\n",
              "  \"padding_value\": 0.0,\n",
              "  \"return_attention_mask\": false,\n",
              "  \"sampling_rate\": 16000,\n",
              "  \"std\": 4.5689974\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\").to(DEVICE)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZETaSypVbBHl",
        "outputId": "a4163937-5e40-4140-d6a1-5cab955b5c16"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASTForAudioClassification(\n",
              "  (audio_spectrogram_transformer): ASTModel(\n",
              "    (embeddings): ASTEmbeddings(\n",
              "      (patch_embeddings): ASTPatchEmbeddings(\n",
              "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ASTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ASTLayer(\n",
              "          (attention): ASTAttention(\n",
              "            (attention): ASTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ASTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ASTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ASTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): ASTMLPHead(\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_features = feature_extractor(wf_prep, TARGET_SAMPLE_RATE, return_tensors=\"pt\").to(DEVICE)\n",
        "sample_features['input_values'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5dFfpx5cUD7",
        "outputId": "515d34d4-ed8f-41a3-9ef9-331f58c2810f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    probs = torch.sigmoid(model(**sample_features).logits)"
      ],
      "metadata": {
        "id": "uiE_guEFeh_D"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_classes = torch.argsort(probs, dim=-1, descending=True).flatten()[:10]\n",
        "top_labels = [(model.config.id2label[id.item()], probs[0, id].item()) for id in top_classes]\n",
        "top_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jY7kN_2exFT",
        "outputId": "926800bc-4999-4fc5-cd57-c0a97ec58b7c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dog', 0.7794268727302551),\n",
              " ('Animal', 0.7416858673095703),\n",
              " ('Domestic animals, pets', 0.6783862113952637),\n",
              " ('Bark', 0.6013599038124084),\n",
              " ('Bow-wow', 0.4377628266811371),\n",
              " ('Canidae, dogs, wolves', 0.19103215634822845),\n",
              " ('Yip', 0.10324634611606598),\n",
              " ('Whimper (dog)', 0.06323514133691788),\n",
              " ('Vehicle', 0.025787750259041786),\n",
              " ('Growling', 0.019477874040603638)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_classes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iod4YE236f0b",
        "outputId": "20cfdfab-a7c2-4884-e2f3-e7aaeac17869"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(74, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Event finder"
      ],
      "metadata": {
        "id": "PE5BmHwm0Wxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EventFinder:\n",
        "    def __init__(self, feature_extractor, model, segment_length_sec):\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.target_sampling_rate = self.feature_extractor.sampling_rate\n",
        "        self.model = model\n",
        "        self.segment_length_sec = segment_length_sec\n",
        "\n",
        "    def compute_probabilities(self, audio_path):\n",
        "        waveform_raw, sampling_rate = torchaudio.load(audio_path)\n",
        "        waveform = preprocess(waveform_raw, sampling_rate, self.target_sampling_rate)\n",
        "\n",
        "        segment_length = self.segment_length_sec * self.target_sampling_rate\n",
        "        segments = [s.numpy() for s in torch.split(waveform, segment_length)]\n",
        "\n",
        "        features = self.feature_extractor(segments, self.target_sampling_rate, return_tensors=\"pt\").to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(model(**features).logits)\n",
        "        return probs\n",
        "\n",
        "    def find_events(self, audio_path):\n",
        "        probs = self.compute_probabilities(audio_path)\n",
        "        top_classes = torch.argsort(probs, dim=-1, descending=True)[:, 0]\n",
        "        top_labels = [model.config.id2label[id.item()] for id in top_classes]\n",
        "        return probs, top_labels\n",
        "\n",
        "finder = EventFinder(feature_extractor, model,\n",
        "                     segment_length_sec=10)\n",
        "probs, top_labels = finder.find_events('/content/freesound_442485_dogs_barking_60sec.wav')\n",
        "top_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjwg1uPDxIKw",
        "outputId": "6a340add-8a16-45a2-cf9d-93c078bcc3a1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dog', 'Dog', 'Dog', 'Animal', 'Dog', 'Dog']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs, top_labels = finder.find_events('/content/recorded_street_150sec.wav')\n",
        "top_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afMdBvpm6og1",
        "outputId": "baafc5d7-4995-44c3-b8fe-e12c430bc4ca"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vehicle',\n",
              " 'Traffic noise, roadway noise',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Traffic noise, roadway noise',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Vehicle',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Speech',\n",
              " 'Speech']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs, top_labels = finder.find_events('/content/freesound_471408_birds_90sec.wav')\n",
        "top_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rle_n6S7BC6",
        "outputId": "b8c1ce2f-ed9e-4604-e52f-51969a4a3703"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Music',\n",
              " 'Bird',\n",
              " 'Crow',\n",
              " 'Crow',\n",
              " 'Environmental noise',\n",
              " 'Crow',\n",
              " 'Bird',\n",
              " 'Environmental noise',\n",
              " 'Crow',\n",
              " 'Caw']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IDUzBCgw8AhU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}