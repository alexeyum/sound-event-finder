{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile"
      ],
      "metadata": {
        "id": "CM0xUzxcrztF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z6Ro5qEGUi9L"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./drive/MyDrive/Projects/MiniSoundFinder/lib/')\n",
        "\n",
        "import classifiers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_path = './drive/MyDrive/Projects/MiniSoundFinder/experiments/basic_convnet_01'\n",
        "\n",
        "model = classifiers.BasicConvNet(input_channels=1, output_size=10)\n",
        "weights_path = os.path.join(experiment_path, 'model.pth')\n",
        "model.load_state_dict(torch.load(weights_path, map_location=torch.device(\"cpu\")))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj40Gsztr2uE",
        "outputId": "e68890b5-46eb-49a7-e3b4-439b4a5301f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BasicConvNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv1d(1, 4, kernel_size=(80,), stride=(64,), bias=False)\n",
              "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv1d(4, 16, kernel_size=(3,), stride=(4,), bias=False)\n",
              "    (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Conv1d(16, 16, kernel_size=(3,), stride=(4,), bias=False)\n",
              "    (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU()\n",
              "    (9): AdaptiveMaxPool1d(output_size=16)\n",
              "  )\n",
              "  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model returns log-softmax, need to apply exp to it\n",
        "\n",
        "class ModelProbabilities(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.exp(self.model(x))\n",
        "\n",
        "model_prob = ModelProbabilities(model)"
      ],
      "metadata": {
        "id": "bBOJ-Fl3r4o1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 384000\n",
        "\n",
        "sample_input = torch.distributions.uniform.Uniform(-10000, 10000).sample((1, 1, MAX_LENGTH))"
      ],
      "metadata": {
        "id": "62XKT81fspXt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FTO1720wa7e",
        "outputId": "8da78610-4b02-4c7b-97c3-2b8ead7c9632"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-645727.6250, -547960.2500, -600927.5000, -555259.0000, -149520.8594,\n",
              "         -533245.5000, -775297.8750,       0.0000, -959467.5000, -474524.5938]],\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_prob(sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWyHZtrtuIv_",
        "outputId": "f41e9211-04b0-487c-969f-ed6b4fd60907"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<ExpBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traced_script_module = torch.jit.trace(model_prob, sample_input)"
      ],
      "metadata": {
        "id": "cE1pYmsEtRta"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traced_script_module_optimized = optimize_for_mobile(traced_script_module)"
      ],
      "metadata": {
        "id": "pO5jnwINtTX5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = './drive/MyDrive/Projects/MiniSoundFinder/exports/'\n",
        "\n",
        "\n",
        "traced_script_module_optimized._save_for_lite_interpreter(\n",
        "    os.path.join(output_path, 'basic_convnet.pt'))"
      ],
      "metadata": {
        "id": "lbWZ22RY3kcE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference speed"
      ],
      "metadata": {
        "id": "dfKRCKClWhKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(1000):\n",
        "    inp = torch.distributions.uniform.Uniform(-10000, 10000).sample((1, 1, MAX_LENGTH))\n",
        "    out = model(inp)"
      ],
      "metadata": {
        "id": "f_k-ZHTY3-1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d83655-fbd6-4607-824c-f41e0deee1cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.37 s, sys: 24.9 ms, total: 6.39 s\n",
            "Wall time: 6.93 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# time collected from mobile samples\n",
        "t = [0.96, 0.3, 0.6, 0.17]\n",
        "print(sum(t) / len(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm-PCqXoWtiY",
        "outputId": "3d2cb1a6-d8e0-4e3e-d3de-e7c8253fb81a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Average inference time GPU: 0.006 sec/sample\n",
        "- Average inference time mobile: 0.5 sec/sample\n",
        "- Approximate mobile slowdown: x100"
      ],
      "metadata": {
        "id": "gKzLmcEpW8SV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQKgkhi3XsaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}